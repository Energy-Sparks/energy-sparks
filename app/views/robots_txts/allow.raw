# See http://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# To ban all spiders from the entire site uncomment the next two lines:
# User-agent: *
# Disallow: /

Sitemap: https://energysparks.uk/sitemap.xml.gz

User-agent: *
Disallow: /admin/
Disallow: /rails/*
Disallow: /schools/scoreboard
Disallow: /schools/*/analysis
Disallow: /schools/*/find_out_more/*
Disallow: /schools/*/chart.json
Disallow: /schools/*/usage
Disallow: /schools/*/advice
Disallow: /schools/*/advice/*
Disallow: /schools/*/school_targets
Disallow: /pupils/schools/*/analysis
Disallow: /benchmark
Disallow: /all_benchmarks
Disallow: /users/sign_in
Disallow: /activity_types/search
Disallow: /compare/*
Disallow: /comparisons

User-agent: SemrushBot
Disallow: /

User-agent: PetalBot
Disallow: /

User-agent: serpstatbot
Disallow: /

User-agent: barkrowler
Disallow: /

User-agent: Bytespider
Disallow: /

User-agent: AhrefsBot
Disallow: /

User-agent: dotbot
Disallow: /

User-agent: rogerbot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: DataForSeoBot
Disallow: /

User-agent: YandexBot
Disallow: /

User-agent: SeekportBot
Disallow: /

User-agent: GPTBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: OAI-SearchBot
Disallow: /

User-agent: ImagesiftBot
Disallow: /

User-agent: ClaudeBot
Disallow: /

User-agent: Scrapy
Disallow: /
